{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPm6dEyfuOlC9RALefyhB1z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamsungmin/DataTrainAnalysis/blob/main/project_week15_RAG_%EC%B2%B4%EC%9D%B8_%EA%B5%AC%EC%84%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. 프로세스 설계 및 데이터 로드**\n",
        "\n",
        "<aside>\n",
        "\n",
        "**진행 프로세스**\n",
        "\n",
        "사내 업무 매뉴얼, 정책 문서, 회의 요약, 기술자료 등의 CSV 기반 데이터를 활용하여 사내 정보 검색 및 요약 AI 챗봇의 학습용 데이터셋을 구축합니다.\n",
        "각 문서의 본문과 부가정보(작성자, 부서, 날짜, 카테고리 등)를 포함하는 CSV 파일(documents.csv)을 LangChain RAG 구조에 맞게 전처리 및 문서화합니다.\n",
        "\n",
        "- documents.csv 파일을 불러와 행을 하나의 사내 정보 단위 문서(Document) 로 구성합니다.\n",
        "    - 본문 컬럼(text, content, body 중 존재하는 항목)을 자동 탐색하여 page_content 로 지정\n",
        "    - 나머지 컬럼은 metadata 로 분리하여 문서의 속성 정보(작성자, 부서, 문서유형 등)로 저장\n",
        "    - 각 Document는 page_content(본문) + metadata(속성정보)의 구조로 통합\n",
        "- 모든 문서를 LangChain의 Document 객체 리스트(docs)로 저장하여 RAG 파이프라인의 입력 데이터로 활용합니다.\n",
        "    - 전체 Document 개수와 일부 샘플의 본문, 메타데이터를 출력하여 로드 결과 검증\n",
        "</aside>"
      ],
      "metadata": {
        "id": "cFJFwF6k8rDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv('/content/documents.csv', encoding='euc-kr')\n",
        "    print(f\"Successfully loaded documents.csv with 'euc-kr' encoding. Number of rows: {len(df)}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading file with 'euc-kr' encoding: {e}\")\n",
        "    df = None\n",
        "\n",
        "\n",
        "docs = []\n",
        "\n",
        "if df is not None:\n",
        "    # Identify potential text columns\n",
        "    text_columns = ['text', 'content', 'body']\n",
        "    found_text_column = None\n",
        "    for col in text_columns:\n",
        "        if col in df.columns:\n",
        "            found_text_column = col\n",
        "            break\n",
        "\n",
        "    if found_text_column:\n",
        "        print(f\"본문 컬럼 : {found_text_column}\")\n",
        "        # Iterate over rows and create Document objects\n",
        "        for index, row in df.iterrows():\n",
        "            page_content = str(row[found_text_column])\n",
        "\n",
        "            # Extract metadata\n",
        "            metadata = row.drop(found_text_column).to_dict()\n",
        "\n",
        "            # Create Document object\n",
        "            doc = Document(page_content=page_content, metadata=metadata)\n",
        "            docs.append(doc)\n",
        "\n",
        "        print(f\"총 {len(docs)} 개 행을 읽었습니다.\")\n",
        "\n",
        "        # Verify results by printing a sample\n",
        "        if docs:\n",
        "            print(\"샘플 문서:\")\n",
        "            print(docs[0])\n",
        "        else:\n",
        "            print(\"No documents were created.\")\n",
        "\n",
        "    else:\n",
        "        print(\"Error: Could not find a suitable text column (text, content, or body) in the CSV.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZsGmmwj8sSH",
        "outputId": "f55c3b26-451c-41ba-93c2-a3a197146246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded documents.csv with 'euc-kr' encoding. Number of rows: 11\n",
            "본문 컬럼 : content\n",
            "총 11 개 행을 읽었습니다.\n",
            "샘플 문서:\n",
            "page_content='2024년 하반기 인사평가는 9월 1일부터 10월 31일까지 진행됩니다. 평가 항목은 업무성과(60%), 역량평가(30%), 동료평가(10%)로 구성됩니다. 업무성과는 상반기에 설정한 KPI 달성도를 기준으로 평가하며, S/A/B/C/D 5단계로 구분합니다. 역량평가는 리더십, 협업능력, 문제해결능력, 전문성 4개 영역에서 평가됩니다. 평가 결과는 11월 15일 개별 통보되며, 이의신청 기간은 11월 20일까지입니다. 평가 결과는 연말 성과급 및 2025년 연봉 책정에 반영됩니다.' metadata={'title': '2024년 하반기 인사평가 가이드라인', 'category': '인사', 'department': '인사팀', 'author': '김민수', 'created_date': '2024-08-15', 'updated_date': '2024-08-20', 'tags': '인사평가,KPI,성과관리,연봉', 'file_path': '/docs/hr/2024_performance_review.pdf', 'access_level': 'all'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "55351e32",
        "outputId": "64ee5f06-5a00-4264-926c-d0f906f415f3"
      },
      "source": [
        "%pip install faiss-cpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. 임베딩생성**\n",
        "\n",
        "<aside>\n",
        "\n",
        "**진행 프로세스**\n",
        "\n",
        "각 문서의 본문과 부가정보(작성자, 부서, 작성일, 문서유형 등)를 포함한 CSV 데이터를 **Document 객체로 구조화**한 후, 이를 **청크 단위로 분할하고 벡터 인덱스로 저장**합니다. 청크 분할 방식, 임베딩 모델, 벡터DB는 데이터 특성에 맞게 적절히 선택합니다.\n",
        "\n",
        "- RAG에 최적화된 크기로 텍스트를 청크화한 뒤, 각 청크를 **의미 벡터(embedding)** 로 변환하여 결과물을 저장합니다.\n",
        "    - chunks_data.pkl : 청크 분할 결과 저장 파일\n",
        "    - 전체 청크 개수, 벡터 차원, 배열 크기 등을 출력해 변환이 정상적으로 이루어졌는지 확인하고\n",
        "        \n",
        "        일부 샘플 벡터(예: 첫 번째 청크의 앞 10개 값)를 출력하여 임베딩 품질검증\n",
        "        \n",
        "- 벡터DB를 재사용할수 있도록 저장한뒤, 벡터 차원, 배열 크기 등을 출력해 변환이 정상적으로 이루어졌는지 확인합니다.\n",
        "    - faiss.db (db는 사용자 선택)\n",
        "</aside>"
      ],
      "metadata": {
        "id": "IkrFw8od9yc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "# Define chunking parameters\n",
        "chunk_size = 500\n",
        "chunk_overlap = 50\n",
        "\n",
        "# Initialize text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")\n",
        "\n",
        "# Split documents into chunks\n",
        "chunks = text_splitter.split_documents(docs)\n",
        "\n",
        "print(f\"총 {len(chunks)} 개의 청크로 분할되었습니다.\")\n",
        "\n",
        "# Initialize embedding model (using a Korean-friendly model)\n",
        "# You might need to install the required libraries: pip install sentence-transformers\n",
        "model_name = \"jhgan/ko-sroberta-multitask\"\n",
        "model_kwargs = {'device': 'cpu'} # Use 'cuda' if you have a GPU\n",
        "encode_kwargs = {'normalize_embeddings': True}\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs=model_kwargs,\n",
        "    encode_kwargs=encode_kwargs\n",
        ")\n",
        "\n",
        "# Create embeddings and build FAISS index\n",
        "# This might take some time depending on the number of chunks\n",
        "print(\"임베딩 생성 및 FAISS 인덱스 구축 중...\")\n",
        "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "print(\"FAISS 인덱스 구축 완료.\")\n",
        "\n",
        "# Save the FAISS index\n",
        "faiss_index_path = \"faiss_index\"\n",
        "vectorstore.save_local(faiss_index_path)\n",
        "print(f\"FAISS 인덱스가 '{faiss_index_path}' 경로에 저장되었습니다.\")\n",
        "\n",
        "# Optional: Save chunks data (for verification or later use)\n",
        "chunks_data_path = \"chunks_data.pkl\"\n",
        "with open(chunks_data_path, \"wb\") as f:\n",
        "    pickle.dump(chunks, f)\n",
        "print(f\"청크 데이터가 '{chunks_data_path}' 경로에 저장되었습니다.\")\n",
        "\n",
        "# Verify results\n",
        "print(f\"전체 청크 개수: {len(chunks)}\")\n",
        "# Get vector dimension (assuming all vectors have the same dimension)\n",
        "if chunks:\n",
        "    sample_embedding = embeddings.embed_query(chunks[0].page_content)\n",
        "    vector_dimension = len(sample_embedding)\n",
        "    print(f\"벡터 차원: {vector_dimension}\")\n",
        "    print(f\"저장된 FAISS 인덱스 경로: {faiss_index_path}\")\n",
        "    print(f\"저장된 청크 데이터 경로: {chunks_data_path}\")\n",
        "\n",
        "    # Print sample vector (first 10 values of the first chunk's embedding)\n",
        "    print(\"\\n샘플 벡터 (첫 번째 청크의 앞 10개 값):\")\n",
        "    print(sample_embedding[:10])\n",
        "else:\n",
        "    print(\"청크가 생성되지 않아 벡터 정보를 확인할 수 없습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ezn9-hlY9zDK",
        "outputId": "aa844653-bc48-444d-9459-37b42fce7188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 11 개의 청크로 분할되었습니다.\n",
            "임베딩 생성 및 FAISS 인덱스 구축 중...\n",
            "FAISS 인덱스 구축 완료.\n",
            "FAISS 인덱스가 'faiss_index' 경로에 저장되었습니다.\n",
            "청크 데이터가 'chunks_data.pkl' 경로에 저장되었습니다.\n",
            "전체 청크 개수: 11\n",
            "벡터 차원: 768\n",
            "저장된 FAISS 인덱스 경로: faiss_index\n",
            "저장된 청크 데이터 경로: chunks_data.pkl\n",
            "\n",
            "샘플 벡터 (첫 번째 청크의 앞 10개 값):\n",
            "[-0.03705906867980957, 0.02856399491429329, -0.05304097384214401, -0.04996252804994583, 0.024541465565562248, -0.010610361583530903, 0.04500309005379677, 0.0329958014190197, 0.028273243457078934, 0.009366557002067566]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.  Retriever(검색기) 구현**\n",
        "\n",
        "<aside>\n",
        "\n",
        "**진행 프로세스**\n",
        "\n",
        "**저장된 벡터 인덱스를 불러와**, LangChain을 이용해 **리트리버(Retriever)** 를 구성합니다.  이 리트리버는 사용자의 질문(query)을 임베딩 후, 의미적으로 유사한 문서를 검색하여 **RAG 파이프라인의 입력**으로 제공합니다.\n",
        "\n",
        "- 저장된 로컬 벡터DB(faiss_db) 를 불러와 **LangChain의 Retriever(검색기) 로 변환**합니다.\n",
        "    - as_retriever() 메서드를 사용하여 의미기반 검색이 가능하도록 구성\n",
        "    - 검색 유형은 similarity로 설정하여 코사인 유사도 기반의 결과 3개의 관련문서 반환\n",
        "- 각 문서의 **본문(page_content)** 과 **메타데이터(metadata)** 를 함께 검토하여 검색 결과의 정확성과 일관성을 확인합니다.\n",
        "    - **메타데이터 필터링**을 통해 부서, 작성일, 문서유형 등 특정 조건에 따라 결과를 선별하여 검색 품질을 평가\n",
        "\n",
        "**결과물**\n",
        "\n",
        "- 질문: query = \"2024년 인사평가 가이드라인에 대해 알려줘”\n",
        "</aside>"
      ],
      "metadata": {
        "id": "2GSDGyMB_9DE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# Define the path to the saved FAISS index\n",
        "faiss_index_path = \"faiss_index\"\n",
        "\n",
        "# Initialize the same embedding model used for creating the index\n",
        "model_name = \"jhgan/ko-sroberta-multitask\"\n",
        "model_kwargs = {'device': 'cpu'} # Use 'cuda' if you have a GPU\n",
        "encode_kwargs = {'normalize_embeddings': True}\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs=model_kwargs,\n",
        "    encode_kwargs=encode_kwargs\n",
        ")\n",
        "\n",
        "# Load the FAISS index\n",
        "try:\n",
        "    vectorstore = FAISS.load_local(faiss_index_path, embeddings, allow_dangerous_deserialization=True)\n",
        "    print(f\"Successfully loaded FAISS index from '{faiss_index_path}'.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading FAISS index: {e}\")\n",
        "    vectorstore = None\n",
        "\n",
        "\n",
        "# Convert the vectorstore to a retriever\n",
        "if vectorstore is not None:\n",
        "    retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
        "    print(\"FAISS vectorstore has been converted to a retriever.\")\n",
        "\n",
        "    # Define a sample query\n",
        "    query = \"2024년 인사평가 가이드라인에 대해 알려줘\"\n",
        "    print(f\"Query: {query}\")\n",
        "\n",
        "    # Perform a search using the retriever\n",
        "    if retriever:\n",
        "        retrieved_docs = retriever.invoke(query)\n",
        "\n",
        "        # Print the retrieved documents\n",
        "        print(\"Retrieved Documents:\")\n",
        "        if retrieved_docs:\n",
        "            for i, doc in enumerate(retrieved_docs):\n",
        "                print(f\"--- Document {i+1} ---\")\n",
        "                print(f\"Page Content: {doc.page_content}\")\n",
        "                print(f\"Metadata: {doc.metadata}\")\n",
        "                print(\"-\" * 20)\n",
        "        else:\n",
        "            print(\"No documents were retrieved for the given query.\")\n",
        "    else:\n",
        "        print(\"Retriever could not be created.\")\n",
        "else:\n",
        "    print(\"Vectorstore could not be loaded, so retriever could not be created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8O0yUeD_92V",
        "outputId": "248fbe4f-db2c-45d0-90b9-402351a07e5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded FAISS index from 'faiss_index'.\n",
            "FAISS vectorstore has been converted to a retriever.\n",
            "Query: 2024년 인사평가 가이드라인에 대해 알려줘\n",
            "Retrieved Documents:\n",
            "--- Document 1 ---\n",
            "Page Content: 2024년 하반기 인사평가는 9월 1일부터 10월 31일까지 진행됩니다. 평가 항목은 업무성과(60%), 역량평가(30%), 동료평가(10%)로 구성됩니다. 업무성과는 상반기에 설정한 KPI 달성도를 기준으로 평가하며, S/A/B/C/D 5단계로 구분합니다. 역량평가는 리더십, 협업능력, 문제해결능력, 전문성 4개 영역에서 평가됩니다. 평가 결과는 11월 15일 개별 통보되며, 이의신청 기간은 11월 20일까지입니다. 평가 결과는 연말 성과급 및 2025년 연봉 책정에 반영됩니다.\n",
            "Metadata: {'title': '2024년 하반기 인사평가 가이드라인', 'category': '인사', 'department': '인사팀', 'author': '김민수', 'created_date': '2024-08-15', 'updated_date': '2024-08-20', 'tags': '인사평가,KPI,성과관리,연봉', 'file_path': '/docs/hr/2024_performance_review.pdf', 'access_level': 'all'}\n",
            "--------------------\n",
            "--- Document 2 ---\n",
            "Page Content: 개인정보 보호법 개정에 따라 당사의 개인정보 처리방침을 다음과 같이 개정합니다. 시행일: 2024년 11월 1일. 주요 변경사항: 1) 개인정보 수집 항목 명시 강화 - 필수 항목과 선택 항목 명확히 구분. 2) 보유 기간 구체화 - 회원정보는 회원 탈퇴 시까지, 거래정보는 5년. 3) 제3자 제공 동의 절차 강화 - 제공 목적, 항목, 보유기간 사전 고지. 4) 개인정보 열람·정정·삭제 요구권 안내 강화. 5) 만 14세 미만 아동의 개인정보 처리 시 법정대리인 동의 필수. 6) 개인정보 유출 시 72시간 이내 통지 의무. 기존 회원에게는 이메일과 앱 푸시로 개정 내용을 안내하며, 30일간 거부 의사 표시 기회를 제공합니다.\n",
            "Metadata: {'title': '개인정보 처리방침 개정안', 'category': '법무', 'department': '법무팀', 'author': '윤지혜', 'created_date': '2024-10-15', 'updated_date': '2024-10-18', 'tags': '개인정보,법무,컴플라이언스,GDPR', 'file_path': '/docs/legal/privacy_policy_revision_2024.pdf', 'access_level': 'manager'}\n",
            "--------------------\n",
            "--- Document 3 ---\n",
            "Page Content: 2024년 4분기 사내 교육 프로그램을 안내합니다. 1) 직무 교육: 각 직무별 전문성 강화 과정. 개발자는 최신 프레임워크, 마케터는 데이터 분석, 영업은 협상 스킬 등. 2) 리더십 교육: 팀장 이상 대상, 피플 매니지먼트, 전략적 사고, 코칭 스킬. 3) 어학 교육: 영어/중국어 회화반 운영, 레벨 테스트 후 반 배정. 회사 지원 50%, 개인 부담 50%. 4) 자기계발 지원금: 연 100만원 한도 내에서 외부 교육, 자격증 취득 비용 지원. 5) 사내 세미나: 월 1회 외부 전문가 초청 세미나 개최. 신청 방법: HR 포털에서 온라인 신청, 선착순 마감. 교육 이수 시 인사 평가 시 가점 부여.\n",
            "Metadata: {'title': '사내 교육 프로그램 안내', 'category': '인사', 'department': '교육팀', 'author': '김민수', 'created_date': '2024-10-08', 'updated_date': '2024-10-12', 'tags': '교육,자기계발,HR,역량개발', 'file_path': '/docs/hr/training_program_Q4_2024.pdf', 'access_level': 'all'}\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. RAG 체인 구성**\n",
        "\n",
        "<aside>\n",
        "\n",
        "**진행 프로세스**\n",
        "\n",
        "사내 문서 검색 및 요약 AI 챗봇의 마지막 단계에서는 **벡터DB(faiss_db)**를 기반으로 요약형 RAG 체인을 구성하여, 사용자의 질문에 의미적으로 관련된 문서를 검색하고 핵심 요약 응답을 생성합니다.\n",
        "**캐시 정책은 “반복 질의는 장기 저장, 일회성 질의는 단기 캐시**” 방식으로 설계해 효율성과 리소스 절약을 동시에 달성합니다.  또한 검색 완료 후 LLM 호출 직전에 **캐시**를 적용하여 최신 검색 결과를 유지하면서 불필요한 재계산을 방지합니다.\n",
        "\n",
        "- 검색된 데이터의 맥락을 LLM이 이해하고 정제된 답변으로 변환하는 역할을 수행하여, 사내문서 내 핵심정보를 요약형 자연어 응답으로 생성합니다.\n",
        "    - ChatPromptTemplate 을 사용해 “사용자 질문 + 검색된 문서 내용(context)”을 하나의 입력으로 통합하는 프롬프트 구조를 정의\n",
        "- **메모리 캐시 전략(Cache Strategy)** 을 적용하여 검색·요약 성능과 응답 속도를 최적화합니다.\n",
        "    - **InMemoryCache** 를 통해 동일한 질의 반복 시 결과를 즉시 재사용하도록 구성하여 불필요한 LLM 호출을 최소화\n",
        "    - **SQLiteCache** 나 파일 기반 캐시를 추가 적용하면, 세션이 종료되어도 과거 검색·요약 결과를 재활용\n",
        "    - 캐시 정책은 “**자주 반복되는 사내 질의(FAQ, 절차 안내 등)** 는 장기 저장 / 일회성 질의는 세션 단기 캐시” 방식으로 설계하여, 처리 효율성과 리소스 절약을 동시에 확보합니다.\n",
        "    - 캐시 저장 및 갱신 시점은 **검색 완료 후 LLM 호출 직전**에 배치하여, 최신 검색 결과를 유지하면서도 불필요한 재계산을 방지합니다.\n",
        "</aside>"
      ],
      "metadata": {
        "id": "MvegxE1RAKGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "# from langchain_community.llms import Ollama # 주석 처리 또는 삭제\n",
        "from langchain_openai import ChatOpenAI # OpenAI Chat 모델 사용\n",
        "from langchain.globals import set_llm_cache\n",
        "from langchain_community.cache import InMemoryCache\n",
        "import os\n",
        "from google.colab import userdata # 코랩 Secrets에서 API 키 가져오기\n",
        "\n",
        "# Set up caching\n",
        "set_llm_cache(InMemoryCache())\n",
        "print(\"InMemoryCache가 설정되었습니다.\")\n",
        "\n",
        "# Define the prompt template\n",
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "print(\"ChatPromptTemplate가 정의되었습니다.\")\n",
        "\n",
        "# Initialize the language model (using OpenAI API)\n",
        "# Get API key from Colab Secrets\n",
        "try:\n",
        "    openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "    if not openai_api_key:\n",
        "        raise ValueError(\"OPENAI_API_KEY not found in Colab Secrets.\")\n",
        "\n",
        "    # Use ChatOpenAI for chat models\n",
        "    llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=openai_api_key) # 또는 \"gpt-3.5-turbo\" 등 다른 모델 사용\n",
        "    print(f\"OpenAI 모델 '{llm.model_name}' 이(가) 초기화되었습니다.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"OpenAI 모델 초기화 오류: {e}\")\n",
        "    llm = None\n",
        "    print(\"코랩 Secrets에 'OPENAI_API_KEY'를 올바르게 설정했는지 확인하세요.\")\n",
        "\n",
        "\n",
        "# Create the RAG chain\n",
        "if llm is not None and 'retriever' in locals():\n",
        "    rag_chain = (\n",
        "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "        | prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "    print(\"RAG 체인이 구성되었습니다.\")\n",
        "\n",
        "    # Define a sample query\n",
        "    query = \"2024년 인사평가 가이드라인에 대해 알려줘\"\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "\n",
        "    # Invoke the RAG chain\n",
        "    print(\"RAG 체인 호출 중...\")\n",
        "    try:\n",
        "        response = rag_chain.invoke(query)\n",
        "        print(\"\\n응답:\")\n",
        "        print(response)\n",
        "    except Exception as e:\n",
        "        print(f\"RAG 체인 호출 오류: {e}\")\n",
        "\n",
        "else:\n",
        "    if llm is None:\n",
        "        print(\"LLM (OpenAI)이 초기화되지 않아 RAG 체인을 구성할 수 없습니다.\")\n",
        "    if 'retriever' not in locals():\n",
        "        print(\"Retriever가 정의되지 않아 RAG 체인을 구성할 수 없습니다. 이전 단계를 먼저 완료해주세요.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJbdPRq7AMUj",
        "outputId": "ed1d5991-5996-4b5b-b137-9abb9215cdf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "InMemoryCache가 설정되었습니다.\n",
            "ChatPromptTemplate가 정의되었습니다.\n",
            "OpenAI 모델 'gpt-4o-mini' 이(가) 초기화되었습니다.\n",
            "RAG 체인이 구성되었습니다.\n",
            "\n",
            "Query: 2024년 인사평가 가이드라인에 대해 알려줘\n",
            "RAG 체인 호출 중...\n",
            "\n",
            "응답:\n",
            "2024년 하반기 인사평가는 9월 1일부터 10월 31일까지 진행됩니다. 평가 항목은 다음과 같이 구성됩니다:\n",
            "- 업무성과: 60% (상반기에 설정한 KPI 달성도를 기준으로 평가)\n",
            "- 역량평가: 30% (리더십, 협업능력, 문제해결능력, 전문성 4개 영역에서 평가)\n",
            "- 동료평가: 10%\n",
            "\n",
            "평가는 S/A/B/C/D 5단계로 구분되며, 평가 결과는 11월 15일에 개별 통보됩니다. 이의신청 기간은 11월 20일까지입니다. 평가 결과는 연말 성과급 및 2025년 연봉 책정에 반영됩니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0d2d0368",
        "outputId": "ef6b999e-8f9d-49a9-b014-75f0e028a068"
      },
      "source": [
        "%pip install langchain-openai"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.0.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.0.2)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (0.4.38)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (2.11.10)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (4.15.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.5)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-openai) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-openai) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.5.0)\n",
            "Downloading langchain_openai-1.0.1-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-1.0.1\n"
          ]
        }
      ]
    }
  ]
}
